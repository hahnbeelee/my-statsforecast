{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark\n",
    "\n",
    "> Run StatsForecast distributedly on top of Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StatsForecast works on top of Spark, Dask, and Ray through [Fugue](https://github.com/fugue-project/fugue/). StatsForecast will read the input DataFrame and use the corresponding engine. For example, if the input is a Spark DataFrame, StatsForecast will use the existing Spark session to run the forecast.\n",
    "\n",
    "A benchmark (with older syntax) can be found [here](https://towardsdatascience.com/distributed-forecast-of-1m-time-series-in-under-15-minutes-with-spark-nixtla-and-fugue-e9892da6fd5c) where we forecasted one million timeseries in under 15 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "As long as Spark is installed and configured, StatsForecast will be able to use it. If executing on a distributed Spark cluster, make use the `statsforecast` library is installed across all the workers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StatsForecast on Pandas\n",
    "\n",
    "Before running on Spark, it's recommended to test on a smaller Pandas dataset to make sure everything is working. This example also helps show the small differences when using Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>AutoETS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-08-10</td>\n",
       "      <td>5.261609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-08-11</td>\n",
       "      <td>6.196357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-08-12</td>\n",
       "      <td>0.282309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-08-13</td>\n",
       "      <td>1.264195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-08-14</td>\n",
       "      <td>2.262453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ds   AutoETS\n",
       "unique_id                     \n",
       "0         2000-08-10  5.261609\n",
       "0         2000-08-11  6.196357\n",
       "0         2000-08-12  0.282309\n",
       "0         2000-08-13  1.264195\n",
       "0         2000-08-14  2.262453"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsforecast.core import StatsForecast\n",
    "from statsforecast.models import ( \n",
    "    AutoARIMA,\n",
    "    AutoETS,\n",
    ")\n",
    "from statsforecast.utils import generate_series\n",
    "\n",
    "n_series = 4\n",
    "horizon = 7\n",
    "\n",
    "series = generate_series(n_series)\n",
    "\n",
    "sf = StatsForecast(\n",
    "    models=[AutoETS(season_length=7)],\n",
    "    freq='D',\n",
    ")\n",
    "sf.forecast(df=series, h=horizon).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing on Spark\n",
    "\n",
    "To run the forecasts distributed on Spark, just pass in a Spark DataFrame instead. Instead of having the `unique_id` as an index, it needs to be a column because Spark has no index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+----------+\n",
      "|unique_id|                 ds|   AutoETS|\n",
      "+---------+-------------------+----------+\n",
      "|        1|2000-04-07 00:00:00|  4.312628|\n",
      "|        1|2000-04-08 00:00:00|  5.228625|\n",
      "|        1|2000-04-09 00:00:00|   6.24151|\n",
      "|        1|2000-04-10 00:00:00|0.23369633|\n",
      "|        1|2000-04-11 00:00:00|  1.173954|\n",
      "+---------+-------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make unique_id a column\n",
    "series = series.reset_index()\n",
    "series['unique_id'] = series['unique_id'].astype(str)\n",
    "\n",
    "# Convert to Spark\n",
    "sdf = spark.createDataFrame(series)\n",
    "\n",
    "# Returns a Spark DataFrame\n",
    "sf.forecast(df=sdf, h=horizon, level=[90]).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpful Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some Spark-specific configurations that may help optimize the workload. \n",
    "\n",
    "```\n",
    "\"spark.speculation\": \"true\",\n",
    "\"spark.sql.shuffle.partitions\": \"8000\",\n",
    "\"spark.sql.adaptive.enabled\": \"false\",\n",
    "\"spark.task.cpus\": \"1\"\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
